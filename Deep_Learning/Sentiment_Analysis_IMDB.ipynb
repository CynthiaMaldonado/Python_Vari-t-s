{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Sentiment_Analysis_IMDB.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jsgQ3NlzSsI",
        "colab_type": "text"
      },
      "source": [
        "# IMDB Sentiment Analysis\n",
        "\n",
        "The data is split evenly with 25k reviews intended for training and 25k for testing your classifier. Moreover, each set has 12.5k positive and 12.5k negative reviews.\n",
        "\n",
        "IMDb lets users rate movies on a scale from 1 to 10. To label these reviews the curator of the data labeled anything with ≤ 4 stars as negative and anything with ≥ 7 stars as positive. Reviews with 5 or 6 stars were left out.\n",
        "\n",
        "\n",
        "https://towardsdatascience.com/sentiment-analysis-with-python-part-1-5ce197074184\n",
        "\n",
        "\n",
        "**Import the required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr4rghAuzSsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWL5WpeJzSsr",
        "colab_type": "text"
      },
      "source": [
        "**Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTEYbvJk2L_e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32c3fa46-bd8f-4704-8da4-7b9e353ba9f9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF9axbfHzSsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_train = []\n",
        "for line in open('/content/drive/My Drive/DataSets/full_train.txt', 'r'):\n",
        "    \n",
        "    reviews_train.append(line.strip())\n",
        "    \n",
        "reviews_test = []\n",
        "for line in open('/content/drive/My Drive/DataSets/full_test.txt', 'r'):\n",
        "    \n",
        "    reviews_test.append(line.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqIoJbEh7Cwi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ff4faaf-b9e5-4026-eab7-cc2aaa71db6d"
      },
      "source": [
        "type(reviews_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKeFLbmWzSs_",
        "colab_type": "text"
      },
      "source": [
        "**See one of the elements in the list**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqUYdXJBzStD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "88ed406b-158c-4857-ff3b-7dc975acdee4"
      },
      "source": [
        "reviews_train[172]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"I just can't understand the negative comments about this film. Yes it is a typical boy-meets-girl romance but it is done with such flair and polish that the time just flies by. Henstridge (talk about winning the gene-pool lottery!) is as magnetic and alluring as ever (who says the golden age of cinema is dead?) and Vartan holds his own.<br /><br />There is simmering chemistry between the two leads; the film is most alive when they share a scene - lots! It is done so well that you find yourself willing them to get together...<br /><br />Ignore the negative comments - if you are feeling a bit blue, watch this flick, you will feel so much better. If you are already happy, then you will be euphoric.<br /><br />(PS: I am 33, Male, from the UK and a hopeless romantic still searching for his Princess...)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvMV3j1DzSti",
        "colab_type": "text"
      },
      "source": [
        "The raw text is pretty messy for these reviews so before we can do any analytics we need to clean things up\n",
        "\n",
        "\n",
        "**Use Regular expressions to remove the non text characters, and the html tags**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4yGbvXuzStk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
        "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
        "NO_SPACE = \"\"\n",
        "SPACE = \" \"\n",
        "\n",
        "def preprocess_reviews(reviews):\n",
        "    \n",
        "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
        "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
        "    \n",
        "    return reviews\n",
        "\n",
        "reviews_train_clean = preprocess_reviews(reviews_train)\n",
        "reviews_test_clean = preprocess_reviews(reviews_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDT2cMed9BiO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "946e7d78-74ee-43ad-c830-de01f83a1b05"
      },
      "source": [
        "len(reviews_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5VCrWbYzStw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "766748cf-83f5-4b78-8f4e-cb7abdc0d026"
      },
      "source": [
        "reviews_train_clean[172]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'i just cant understand the negative comments about this film yes it is a typical boy meets girl romance but it is done with such flair and polish that the time just flies by henstridge talk about winning the gene pool lottery is as magnetic and alluring as ever who says the golden age of cinema is dead and vartan holds his own there is simmering chemistry between the two leads the film is most alive when they share a scene   lots it is done so well that you find yourself willing them to get together ignore the negative comments   if you are feeling a bit blue watch this flick you will feel so much better if you are already happy then you will be euphoric ps i am  male from the uk and a hopeless romantic still searching for his princess'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWq0j106zSt9",
        "colab_type": "text"
      },
      "source": [
        "**Vectorization**\n",
        "\n",
        "In order for this data to make sense to our machine learning algorithm we’ll need to convert each review to a numeric representation, which we call vectorization.\n",
        "\n",
        "The simplest form of this is to create one very large matrix with one column for every unique word in your corpus (where the corpus is all 50k reviews in our case). Then we transform each review into one row containing 0s and 1s, where 1 means that the word in the corpus corresponding to that column appears in that review. That being said, each row of the matrix will be very sparse (mostly zeros). This process is also known as one hot encoding. Use the *CountVectorizer* method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkfxgNNVOn0L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd45350c-615c-4929-a8ea-eb149a45c4c0"
      },
      "source": [
        "len(reviews_train_clean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyKEPk_PzSuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "train_counts = count_vect.fit_transform(reviews_train_clean)\n",
        "test_counts = count_vect.transform(reviews_test_clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DoGAEhMzSuL",
        "colab_type": "text"
      },
      "source": [
        "**Modeling**\n",
        "\n",
        "Use a logistic regression to buid a classifier.\n",
        "\n",
        "(1) They’re easy to interpret, \n",
        "\n",
        "(2) linear models tend to perform well on sparse datasets like this one, and\n",
        "\n",
        "(3) they learn very fast compared to other algorithms.\n",
        "\n",
        "\n",
        "Test models with C values of [0.01, 0.05, 0.25, 0.5, 1] and see wich is the best value for C, and calculate the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXh2Ce3CSSjc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f2514624-c7f4-4b3f-cfc3-49b07dc3b492"
      },
      "source": [
        "y = []\n",
        "for i in range(25000):\n",
        "  if i < 12500:\n",
        "    y.append(1)\n",
        "  else:\n",
        "    y.append(0)\n",
        "\n",
        "print(np.unique(y, return_counts=True))\n",
        "len(y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 1]), array([12500, 12500]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7vzX9wzzSuM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "75366c86-9762-4df1-c04f-933480135447"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    train_counts, y, train_size = 0.75\n",
        ")\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    \n",
        "    lr = LogisticRegression(C=c)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
        "        \n",
        "#     Accuracy for C=0.01: 0.87472\n",
        "#     Accuracy for C=0.05: 0.88368\n",
        "#     Accuracy for C=0.25: 0.88016\n",
        "#     Accuracy for C=0.5: 0.87808\n",
        "#     Accuracy for C=1: 0.87648"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.01: 0.87808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.05: 0.88816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.25: 0.88992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.5: 0.88576\n",
            "Accuracy for C=1: 0.88528\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYRiUYzfzSuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7dfd5166-ef6a-487d-df3e-8e49f44d093e"
      },
      "source": [
        "final_model = LogisticRegression(C=0.05)\n",
        "final_model.fit(train_counts, y)\n",
        "print (\"Final Accuracy: %s\" \n",
        "       % accuracy_score(y, final_model.predict(test_counts)))\n",
        "\n",
        "# Final Accuracy: 0.88128"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Accuracy: 0.88152\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0r4jPY_zSuU",
        "colab_type": "text"
      },
      "source": [
        "**Feature importance**\n",
        "\n",
        "\n",
        "Let’s look at the 5 most discriminating words for both positive and negative reviews. We’ll do this by looking at the largest and smallest coefficients, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvj6q9IEzSuW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ccfe6533-0761-4de8-afb6-807c19e97962"
      },
      "source": [
        "feature_to_coef = {\n",
        "    word: coef for word, coef in zip(\n",
        "        count_vect.get_feature_names(), final_model.coef_[0]\n",
        "    )\n",
        "}\n",
        "for best_positive in sorted(\n",
        "    feature_to_coef.items(), \n",
        "    key=lambda x: x[1], \n",
        "    reverse=True)[:5]:\n",
        "    print (best_positive)\n",
        "    \n",
        "#     ('excellent', 0.9288812418118644)\n",
        "#     ('perfect', 0.7934641227980576)\n",
        "#     ('great', 0.675040909917553)\n",
        "#     ('amazing', 0.6160398142631545)\n",
        "#     ('superb', 0.6063967799425831)\n",
        "    \n",
        "for best_negative in sorted(\n",
        "    feature_to_coef.items(), \n",
        "    key=lambda x: x[1])[:5]:\n",
        "    print (best_negative)\n",
        "    \n",
        "#     ('worst', -1.367978497228895)\n",
        "#     ('waste', -1.1684451288279047)\n",
        "#     ('awful', -1.0277001734353677)\n",
        "#     ('poorly', -0.8748317895742782)\n",
        "#     ('boring', -0.8587249740682945)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('excellent', 0.7958045444369413)\n",
            "('perfect', 0.6786958573720847)\n",
            "('superb', 0.5898245415740635)\n",
            "('funniest', 0.5786694510701385)\n",
            "('wonderfully', 0.572924424253522)\n",
            "('waste', -1.2144116608193696)\n",
            "('worst', -1.2068856181717498)\n",
            "('awful', -0.9387920199695935)\n",
            "('disappointment', -0.8843806688093154)\n",
            "('poorly', -0.8696239281219093)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}